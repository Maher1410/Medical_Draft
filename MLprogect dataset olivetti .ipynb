{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Task Learning for Fashion Product Classification\n",
    "\n",
    "This notebook implements a multi-task learning model to classify fashion products by:\n",
    "1. Article Category\n",
    "2. Base Color\n",
    "3. Season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Import required libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model, optimizers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set your paths here\n",
    "IMAGE_DIR = 'path/to/your/images/directory'  # Update this\n",
    "CSV_PATH = 'path/to/your/styles.csv'        # Update this\n",
    "\n",
    "# Load and examine the metadata\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nSample data:\")\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Data analysis and preprocessing\n",
    "def analyze_dataset(df):\n",
    "    print(\"Number of unique values in each category:\")\n",
    "    print(f\"Article Types: {len(df['articleType'].unique())}\")\n",
    "    print(f\"Colors: {len(df['baseColour'].unique())}\")\n",
    "    print(f\"Seasons: {len(df['season'].unique())}\")\n",
    "    \n",
    "    # Plot distribution of categories\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    df['articleType'].value_counts().plot(kind='bar')\n",
    "    plt.title('Article Types Distribution')\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    df['baseColour'].value_counts().plot(kind='bar')\n",
    "    plt.title('Colors Distribution')\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    df['season'].value_counts().plot(kind='bar')\n",
    "    plt.title('Seasons Distribution')\n",
    "    plt.xticks(rotation=90)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "analyze_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Verify images exist and clean dataset\n",
    "def verify_images(df, image_dir):\n",
    "    df['image_path'] = df['filename'].apply(lambda x: os.path.join(image_dir, x))\n",
    "    existing_images = df['image_path'].apply(os.path.exists)\n",
    "    print(f\"Images found: {sum(existing_images)} out of {len(df)}\")\n",
    "    return df[existing_images]\n",
    "\n",
    "df = verify_images(df, IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create label encoders and encode labels\n",
    "article_encoder = LabelEncoder()\n",
    "color_encoder = LabelEncoder()\n",
    "season_encoder = LabelEncoder()\n",
    "\n",
    "df['article_encoded'] = article_encoder.fit_transform(df['articleType'])\n",
    "df['color_encoded'] = color_encoder.fit_transform(df['baseColour'])\n",
    "df['season_encoded'] = season_encoder.fit_transform(df['season'])\n",
    "\n",
    "# Get dimensions for model\n",
    "num_article_categories = len(article_encoder.classes_)\n",
    "num_colors = len(color_encoder.classes_)\n",
    "num_seasons = len(season_encoder.classes_)\n",
    "\n",
    "print(\"Number of categories after encoding:\")\n",
    "print(f\"Articles: {num_article_categories}\")\n",
    "print(f\"Colors: {num_colors}\")\n",
    "print(f\"Seasons: {num_seasons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Define the multi-task model\n",
    "def create_model(num_article_categories, num_colors, num_seasons, img_size=224):\n",
    "    # Input layer\n",
    "    input_layer = layers.Input(shape=(img_size, img_size, 3))\n",
    "    \n",
    "    # Base model\n",
    "    base_model = ResNet50(\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        input_tensor=input_layer\n",
    "    )\n",
    "    base_model.trainable = False\n",
    "    \n",
    "    # Common layers\n",
    "    x = layers.GlobalAveragePooling2D()(base_model.output)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    \n",
    "    # Task-specific branches\n",
    "    article_branch = layers.Dense(256, activation='relu')(x)\n",
    "    article_output = layers.Dense(num_article_categories, activation='softmax', name='article')(article_branch)\n",
    "    \n",
    "    color_branch = layers.Dense(128, activation='relu')(x)\n",
    "    color_output = layers.Dense(num_colors, activation='softmax', name='color')(color_branch)\n",
    "    \n",
    "    season_branch = layers.Dense(64, activation='relu')(x)\n",
    "    season_output = layers.Dense(num_seasons, activation='softmax', name='season')(season_branch)\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(\n",
    "        inputs=input_layer,\n",
    "        outputs=[article_output, color_output, season_output]\n",
    "    )\n",
    "    \n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "        loss={\n",
    "            'article': 'sparse_categorical_crossentropy',\n",
    "            'color': 'sparse_categorical_crossentropy',\n",
    "            'season': 'sparse_categorical_crossentropy'\n",
    "        },\n",
    "        loss_weights={'article': 1.0, 'color': 1.0, 'season': 1.0},\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Create the model\n",
    "model = create_model(num_article_categories, num_colors, num_seasons)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up data generators\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Training generator\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGE_DIR,\n",
    "    x_col='filename',\n",
    "    y_col=['article_encoded', 'color_encoded', 'season_encoded'],\n",
    "    subset='training',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='multi_output'\n",
    ")\n",
    "\n",
    "# Validation generator\n",
    "valid_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=df,\n",
    "    directory=IMAGE_DIR,\n",
    "    x_col='filename',\n",
    "    y_col=['article_encoded', 'color_encoded', 'season_encoded'],\n",
    "    subset='validation',\n",
    "    batch_size=32,\n",
    "    seed=42,\n",
    "    target_size=(224, 224),\n",
    "    class_mode='multi_output'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=3,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=2\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "def plot_training_history(history):\n",
    "    # Plot article classification metrics\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.plot(history.history['article_accuracy'], label='Train (Article)')\n",
    "    plt.plot(history.history['val_article_accuracy'], label='Validation (Article)')\n",
    "    plt.title('Article Classification Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.plot(history.history['color_accuracy'], label='Train (Color)')\n",
    "    plt.plot(history.history['val_color_accuracy'], label='Validation (Color)')\n",
    "    plt.title('Color Classification Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.plot(history.history['season_accuracy'], label='Train (Season)')\n",
    "    plt.plot(history.history['val_season_accuracy'], label='Validation (Season)')\n",
    "    plt.title('Season Classification Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Function to make predictions on a single image\n",
    "def predict_single_image(image_path, model):\n",
    "    # Load and preprocess image\n",
    "    img = tf.keras.preprocessing.image.load_img(\n",
    "        image_path, \n",
    "        target_size=(224, 224)\n",
    "    )\n",
    "    img_array = tf.keras.preprocessing.image.img_to_array(img)\n",
    "    img_array = img_array / 255.0\n",
    "    img_array = np.expand_dims(img_array, 0)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(img_array)\n",
    "    \n",
    "    # Decode predictions\n",
    "    article = article_encoder.inverse_transform([np.argmax(predictions[0])])[0]\n",
    "    color = color_encoder.inverse_transform([np.argmax(predictions[1])])[0]\n",
    "    season = season_encoder.inverse_transform([np.argmax(predictions[2])])[0]\n",
    "    \n",
    "    return {\n",
    "        'article': article,\n",
    "        'color': color,\n",
    "        'season': season\n",
    "    }\n",
    "\n",
    "# Test the model on a sample image\n",
    "sample_image_path = os.path.join(IMAGE_DIR, df['filename'].iloc[0])\n",
    "predictions = predict_single_image(sample_image_path, model)\n",
    "print(\"
